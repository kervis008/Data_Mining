<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Data Mining - Course Summary</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600;700;800&display=swap');
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Poppins', sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #f093fb 100%);
            min-height: 100vh;
            overflow-x: hidden;
        }

        /* Animated background particles */
        .particles {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
            z-index: -1;
        }

        .particle {
            position: absolute;
            width: 4px;
            height: 4px;
            background: rgba(255, 255, 255, 0.7);
            border-radius: 50%;
            animation: float 6s infinite linear;
        }

        @keyframes float {
            0% { transform: translateY(100vh) rotate(0deg); opacity: 0; }
            10% { opacity: 1; }
            90% { opacity: 1; }
            100% { transform: translateY(-100px) rotate(360deg); opacity: 0; }
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            box-shadow: 0 0 50px rgba(0, 0, 0, 0.2);
            border-radius: 20px;
            margin-top: 20px;
            margin-bottom: 20px;
            border: 1px solid rgba(255, 255, 255, 0.3);
        }

        header {
            text-align: center;
            margin-bottom: 40px;
            padding: 50px 0;
            background: linear-gradient(135deg, #4a47a3 0%, #413c69 50%, #2d1b69 100%);
            color: white;
            border-radius: 20px;
            position: relative;
            overflow: hidden;
            transform-style: preserve-3d;
        }

        header::before {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.2), transparent);
            animation: shimmer 3s infinite;
        }

        @keyframes shimmer {
            0% { left: -100%; }
            100% { left: 100%; }
        }

        h1 {
            font-size: 3.5em;
            margin-bottom: 15px;
            text-shadow: 3px 3px 6px rgba(0, 0, 0, 0.3);
            font-weight: 800;
            background: linear-gradient(45deg, #fff, #e0e0e0);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            animation: titleGlow 2s ease-in-out infinite alternate;
        }

        @keyframes titleGlow {
            from { filter: drop-shadow(0 0 10px rgba(255, 255, 255, 0.5)); }
            to { filter: drop-shadow(0 0 20px rgba(255, 255, 255, 0.8)); }
        }

        .subtitle {
            font-size: 1.3em;
            font-style: italic;
            opacity: 0.9;
            font-weight: 300;
        }

        .overview {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: 40px;
            border-radius: 20px;
            margin-bottom: 40px;
            border: 1px solid rgba(74, 71, 163, 0.2);
            position: relative;
            transform: perspective(1000px) rotateX(2deg);
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
            transition: all 0.3s ease;
        }

        .overview:hover {
            transform: perspective(1000px) rotateX(0deg) translateY(-5px);
            box-shadow: 0 20px 50px rgba(0, 0, 0, 0.15);
        }

        .overview h2 {
            color: #4a47a3;
            margin-bottom: 20px;
            font-size: 2.2em;
            font-weight: 700;
            position: relative;
        }

        .overview h2::after {
            content: '';
            position: absolute;
            bottom: -10px;
            left: 0;
            width: 60px;
            height: 4px;
            background: linear-gradient(90deg, #4a47a3, #667eea);
            border-radius: 2px;
        }

        .toc {
            background: linear-gradient(135deg, #fff 0%, #f8f9fa 100%);
            padding: 40px;
            border-radius: 20px;
            margin-bottom: 40px;
            box-shadow: 0 15px 35px rgba(0, 0, 0, 0.1);
            border: 1px solid rgba(74, 71, 163, 0.1);
        }

        .toc h2 {
            color: #4a47a3;
            margin-bottom: 30px;
            font-size: 2.2em;
            text-align: center;
            font-weight: 700;
            position: relative;
        }

        .toc h2::before {
            content: 'üìã';
            font-size: 1.2em;
            margin-right: 15px;
        }

        .toc ol {
            counter-reset: chapter-counter;
            list-style: none;
            padding-left: 0;
            display: grid;
            gap: 15px;
        }

        .toc li {
            counter-increment: chapter-counter;
            padding: 20px;
            background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
            border-radius: 15px;
            border: 2px solid transparent;
            background-clip: padding-box;
            transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275);
            position: relative;
            overflow: hidden;
        }

        .toc li::before {
            content: counter(chapter-counter);
            background: linear-gradient(135deg, #4a47a3 0%, #667eea 100%);
            color: white;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            margin-right: 20px;
            font-weight: 700;
            font-size: 1.1em;
            box-shadow: 0 4px 15px rgba(74, 71, 163, 0.3);
        }

        .toc li:hover {
            transform: translateX(10px) scale(1.02);
            box-shadow: 0 15px 40px rgba(74, 71, 163, 0.2);
            border-color: #4a47a3;
        }

        .toc li::after {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(74, 71, 163, 0.1), transparent);
            transition: all 0.5s ease;
        }

        .toc li:hover::after {
            left: 100%;
        }

        .toc a {
            text-decoration: none;
            color: #333;
            font-weight: 600;
            font-size: 1.2em;
            transition: color 0.3s ease;
        }

        .toc a:hover {
            color: #4a47a3;
        }

        .chapter {
            margin-bottom: 50px;
            padding: 40px;
            background: linear-gradient(135deg, #fff 0%, #f8f9fa 100%);
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.1);
            border: 1px solid rgba(74, 71, 163, 0.1);
            position: relative;
            overflow: hidden;
            transform: perspective(1000px) rotateY(1deg);
            transition: all 0.3s ease;
        }

        .chapter:hover {
            transform: perspective(1000px) rotateY(0deg) translateY(-5px);
            box-shadow: 0 30px 80px rgba(0, 0, 0, 0.15);
        }

        .chapter::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 5px;
            background: linear-gradient(90deg, #4a47a3, #667eea, #764ba2);
        }

        .chapter h2 {
            color: #4a47a3;
            margin-bottom: 25px;
            font-size: 2.5em;
            font-weight: 700;
            background: linear-gradient(135deg, #4a47a3 0%, #667eea 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .chapter h3 {
            color: #666;
            margin-top: 30px;
            margin-bottom: 20px;
            font-size: 1.5em;
            font-weight: 600;
            position: relative;
            padding-left: 25px;
        }

        .chapter h3::before {
            content: '‚ñ∏';
            position: absolute;
            left: 0;
            color: #4a47a3;
            font-size: 1.2em;
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.1); }
        }

        .techniques {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: 25px;
            border-radius: 15px;
            margin: 25px 0;
            border-left: 5px solid #4a47a3;
            box-shadow: 0 5px 20px rgba(0, 0, 0, 0.05);
            transition: all 0.3s ease;
        }

        .techniques:hover {
            transform: translateX(5px);
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
        }

        .techniques h4 {
            color: #4a47a3;
            margin-bottom: 15px;
            font-weight: 600;
            font-size: 1.2em;
        }

        .techniques ul {
            list-style-type: none;
            padding-left: 0;
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 10px;
        }

        .techniques li {
            padding: 8px 0;
            padding-left: 25px;
            position: relative;
            transition: all 0.3s ease;
            border-radius: 5px;
        }

        .techniques li:hover {
            background: rgba(74, 71, 163, 0.1);
            transform: translateX(5px);
        }

        .techniques li::before {
            content: "‚ú®";
            position: absolute;
            left: 0;
            font-weight: bold;
            animation: sparkle 2s infinite;
        }

        @keyframes sparkle {
            0%, 100% { transform: rotate(0deg) scale(1); }
            50% { transform: rotate(180deg) scale(1.2); }
        }

        .github-link {
            display: inline-block;
            background: linear-gradient(135deg, #28a745 0%, #20c997 50%, #17a2b8 100%);
            color: white;
            padding: 15px 30px;
            text-decoration: none;
            border-radius: 50px;
            margin-top: 20px;
            font-weight: 600;
            font-size: 1.1em;
            transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275);
            box-shadow: 0 8px 25px rgba(40, 167, 69, 0.3);
            position: relative;
            overflow: hidden;
        }

        .github-link::before {
            content: "üîó ";
            font-size: 1.2em;
        }

        .github-link::after {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.2), transparent);
            transition: all 0.5s ease;
        }

        .github-link:hover {
            transform: translateY(-3px) scale(1.05);
            box-shadow: 0 15px 40px rgba(40, 167, 69, 0.4);
        }

        .github-link:hover::after {
            left: 100%;
        }

        .algorithms-section {
            background: linear-gradient(135deg, #fff 0%, #f8f9fa 100%);
            padding: 40px;
            border-radius: 20px;
            margin-top: 50px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.1);
            border: 1px solid rgba(74, 71, 163, 0.1);
        }

        .algorithms-section h2 {
            color: #4a47a3;
            margin-bottom: 40px;
            font-size: 2.5em;
            text-align: center;
            font-weight: 700;
            background: linear-gradient(135deg, #4a47a3 0%, #667eea 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .algorithm-category {
            margin-bottom: 40px;
            padding: 30px;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 20px;
            border: 2px solid transparent;
            background-clip: padding-box;
            position: relative;
        }

        .algorithm-category::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: linear-gradient(135deg, #4a47a3, #667eea, #764ba2);
            border-radius: 20px;
            padding: 2px;
            z-index: -1;
        }

        .algorithm-category h3 {
            color: #4a47a3;
            margin-bottom: 25px;
            font-size: 1.8em;
            font-weight: 700;
            text-align: center;
        }

        .algorithm-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }

        .algorithm-card {
            background: linear-gradient(135deg, white 0%, #f8f9fa 100%);
            padding: 25px;
            border-radius: 15px;
            border: 2px solid transparent;
            transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275);
            position: relative;
            overflow: hidden;
            cursor: pointer;
        }

        .algorithm-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: linear-gradient(135deg, #4a47a3, #667eea);
            opacity: 0;
            transition: opacity 0.3s ease;
            z-index: -1;
        }

        .algorithm-card:hover {
            transform: translateY(-10px) scale(1.03);
            box-shadow: 0 20px 50px rgba(74, 71, 163, 0.3);
            border-color: #4a47a3;
        }

        .algorithm-card:hover::before {
            opacity: 0.1;
        }

        .algorithm-card h4 {
            color: #4a47a3;
            margin-bottom: 12px;
            font-size: 1.3em;
            font-weight: 600;
        }

        .algorithm-card p {
            font-size: 0.95em;
            color: #666;
            line-height: 1.6;
        }

        footer {
            text-align: center;
            margin-top: 50px;
            padding: 40px;
            background: linear-gradient(135deg, #4a47a3 0%, #413c69 50%, #2d1b69 100%);
            color: white;
            border-radius: 20px;
            position: relative;
            overflow: hidden;
        }

        footer::before {
            content: '';
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: radial-gradient(circle, rgba(255, 255, 255, 0.1) 0%, transparent 70%);
            animation: rotate 20s linear infinite;
        }

        @keyframes rotate {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .highlight {
            background: linear-gradient(120deg, #a8e6cf 0%, #88d8a3 100%);
            padding: 4px 8px;
            border-radius: 6px;
            font-weight: 600;
            box-shadow: 0 2px 10px rgba(168, 230, 207, 0.4);
        }

        .formula {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: 15px;
            border-radius: 10px;
            font-family: 'Courier New', monospace;
            border-left: 4px solid #4a47a3;
            margin: 15px 0;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
            font-size: 1.1em;
        }

        .scroll-progress {
            position: fixed;
            top: 0;
            left: 0;
            width: 0%;
            height: 4px;
            background: linear-gradient(90deg, #4a47a3, #667eea, #764ba2);
            z-index: 1000;
            transition: width 0.3s ease;
        }

        /* Mobile Responsiveness */
        @media (max-width: 768px) {
            .container {
                padding: 15px;
                margin-top: 10px;
            }
            
            h1 {
                font-size: 2.5em;
            }
            
            .algorithm-grid {
                grid-template-columns: 1fr;
            }
            
            .chapter {
                padding: 25px;
            }
            
            .toc ol {
                grid-template-columns: 1fr;
            }
        }

        /* Smooth scroll behavior */
        html {
            scroll-behavior: smooth;
        }

        /* Custom scrollbar */
        ::-webkit-scrollbar {
            width: 12px;
        }

        ::-webkit-scrollbar-track {
            background: #f1f1f1;
            border-radius: 6px;
        }

        ::-webkit-scrollbar-thumb {
            background: linear-gradient(135deg, #4a47a3, #667eea);
            border-radius: 6px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: linear-gradient(135deg, #667eea, #764ba2);
        }
    </style>
</head>
<body>
    <div class="scroll-progress"></div>
    <div class="particles"></div>
    
    <div class="container">
        <header>
            <h1>Data Mining</h1>
            <p class="subtitle">With Applications in Python - Course Summary</p>
        </header>

        <section class="overview">
            <h2>üìö Course Overview</h2>
            <p>
                <strong>Data Mining</strong> is a comprehensive course that provides an accessible introduction to the field of statistical learning and data mining, essential toolsets for making sense of vast and complex data sets. The course covers a wide range of topics including <span class="highlight">linear regression</span>, <span class="highlight">classification</span>, <span class="highlight">resampling methods</span>, <span class="highlight">shrinkage approaches</span>, <span class="highlight">tree-based methods</span>, <span class="highlight">support vector machines</span>, and <span class="highlight">unsupervised learning</span>. Each chapter includes practical examples using Python programming language, making it ideal for both theoretical understanding and practical application. The course strikes a balance between statistical theory and practical implementation, making it suitable for students and practitioners in data science, machine learning, and statistics.
            </p>
        </section>

        <section class="toc">
            <h2>Table of Contents</h2>
            <ol>
                <li><a href="#chapter1">Introduction</a></li>
                <li><a href="#chapter2">Linear Regression</a></li>
                <li><a href="#chapter3">Classification</a></li>
                <li><a href="#chapter4">Resampling Methods</a></li>
                <li><a href="#chapter5">Linear Model Selection and Regularization</a></li>
                <li><a href="#chapter6">Tree-based Methods</a></li>
                <li><a href="#chapter7">Support Vector Machines</a></li>
                <li><a href="#chapter8">Deep Learning</a></li>
                <li><a href="#chapter9">Unsupervised Learning</a></li>
                <li><a href="#chapter10">Text Mining</a></li>
            </ol>
        </section>

        <main>
            <article id="chapter1" class="chapter">
                <h2>Chapter 1: Introduction</h2>
                <p>This foundational chapter introduces the key concepts and terminology in statistical learning. It establishes the framework for understanding the relationship between inputs and outputs in data analysis.</p>
                
                <h3>üéØ Main Ideas</h3>
                <ul>
                    <li><strong>Statistical Learning:</strong> Methods for understanding relationships between variables</li>
                    <li><strong>Supervised vs Unsupervised Learning:</strong> Distinction between learning with and without output variables</li>
                    <li><strong>Regression vs Classification:</strong> Quantitative vs qualitative response variables</li>
                    <li><strong>Prediction vs Inference:</strong> Different goals of statistical learning</li>
                </ul>

                <div class="techniques">
                    <h4>üîß Key Techniques</h4>
                    <ul>
                        <li>Bias-Variance Tradeoff</li>
                        <li>Training vs Test Error</li>
                        <li>Cross-Validation concepts</li>
                        <li>Curse of Dimensionality</li>
                    </ul>
                </div>

                <h3>üí° Key Takeaways</h3>
                <p>Understanding the fundamental concepts of statistical learning is crucial for applying more advanced techniques. The chapter emphasizes the importance of <span class="highlight">model interpretability</span> and <span class="highlight">prediction accuracy</span> balance.</p>
            </article>

            <article id="chapter2" class="chapter">
                <h2>Chapter 2: Linear Regression</h2>
                <p>Linear regression is one of the most fundamental and widely used statistical learning methods. This chapter covers both simple and multiple linear regression, providing the foundation for understanding relationships between variables.</p>
                
                <h3>üéØ Main Ideas</h3>
                <ul>
                    <li><strong>Simple Linear Regression:</strong> Relationship between two variables</li>
                    <li><strong>Multiple Linear Regression:</strong> Multiple predictors for one response</li>
                    <li><strong>Least Squares:</strong> Method for estimating coefficients</li>
                    <li><strong>Model Assessment:</strong> R-squared, F-statistic, p-values</li>
                </ul>

                <div class="techniques">
                    <h4>üîß Key Techniques</h4>
                    <ul>
                        <li>Ordinary Least Squares (OLS)</li>
                        <li>Residual Analysis</li>
                        <li>Confidence and Prediction Intervals</li>
                        <li>Polynomial Regression</li>
                        <li>Interaction Terms</li>
                    </ul>
                </div>

                <div class="formula">
                    <strong>Linear Model:</strong> Y = Œ≤‚ÇÄ + Œ≤‚ÇÅX‚ÇÅ + Œ≤‚ÇÇX‚ÇÇ + ... + Œ≤‚ÇöX‚Çö + Œµ
                </div>

                <h3>üí° Key Takeaways</h3>
                <p>Linear regression provides interpretable models with clear relationships between predictors and response. Understanding <span class="highlight">assumptions</span> and <span class="highlight">limitations</span> is crucial for proper application.</p>

                <a href="https://github.com/kervis008/Data_Mining/blob/main/Chap2.ipynb" class="github-link">GitHub Lab Notebook - Chapter 2</a>
            </article>

            <article id="chapter3" class="chapter">
                <h2>Chapter 3: Classification</h2>
                <p>Classification methods are used when the response variable is qualitative. This chapter introduces several classification techniques and their applications.</p>
                
                <h3>üéØ Main Ideas</h3>
                <ul>
                    <li><strong>Logistic Regression:</strong> Extension of linear regression for binary outcomes</li>
                    <li><strong>Linear Discriminant Analysis (LDA):</strong> Classification using Bayes' theorem</li>
                    <li><strong>Quadratic Discriminant Analysis (QDA):</strong> More flexible version of LDA</li>
                    <li><strong>K-Nearest Neighbors (KNN):</strong> Non-parametric classification method</li>
                </ul>

                <div class="techniques">
                    <h4>üîß Key Techniques</h4>
                    <ul>
                        <li>Logistic Regression</li>
                        <li>Linear Discriminant Analysis</li>
                        <li>Quadratic Discriminant Analysis</li>
                        <li>K-Nearest Neighbors</li>
                        <li>Naive Bayes</li>
                        <li>ROC Curves and AUC</li>
                    </ul>
                </div>

                <div class="formula">
                    <strong>Logistic Function:</strong> p(X) = e^(Œ≤‚ÇÄ + Œ≤‚ÇÅX) / (1 + e^(Œ≤‚ÇÄ + Œ≤‚ÇÅX))
                </div>

                <h3>üí° Key Takeaways</h3>
                <p>Different classification methods have different strengths. <span class="highlight">Logistic regression</span> is interpretable, <span class="highlight">LDA</span> assumes normality, and <span class="highlight">KNN</span> is non-parametric but requires careful selection of K.</p>

                <a href="https://github.com/kervis008/Data_Mining/blob/main/Chap3.ipynb" class="github-link">GitHub Lab Notebook - Chapter 3</a>
            </article>

            <article id="chapter4" class="chapter">
                <h2>Chapter 4: Resampling Methods</h2>
                <p>Resampling methods are essential tools for model assessment and selection. They allow us to estimate the performance of our models on unseen data.</p>
                
                <h3>üéØ Main Ideas</h3>
                <ul>
                    <li><strong>Cross-Validation:</strong> Estimating test error without a separate test set</li>
                    <li><strong>Bootstrap:</strong> Sampling with replacement to assess uncertainty</li>
                    <li><strong>Leave-One-Out Cross-Validation (LOOCV):</strong> Extreme case of cross-validation</li>
                    <li><strong>k-Fold Cross-Validation:</strong> Practical approach to cross-validation</li>
                </ul>

                <div class="techniques">
                    <h4>üîß Key Techniques</h4>
                    <ul>
                        <li>k-Fold Cross-Validation</li>
                        <li>Leave-One-Out Cross-Validation</li>
                        <li>Bootstrap Sampling</li>
                        <li>Validation Set Approach</li>
                        <li>Time Series Cross-Validation</li>
                    </ul>
                </div>

                <h3>üí° Key Takeaways</h3>
                <p>Resampling methods are crucial for <span class="highlight">model selection</span> and <span class="highlight">performance estimation</span>. Cross-validation helps prevent overfitting and provides more reliable estimates of model performance.</p>

                <a href="https://github.com/kervis008/Data_Mining/blob/main/Chap04.ipynb" class="github-link">GitHub Lab Notebook - Chapter 4</a>
            </article>

            <article id="chapter5" class="chapter">
                <h2>Chapter 5: Linear Model Selection and Regularization</h2>
                <p>This chapter extends linear regression by introducing methods for improving model performance through variable selection and regularization techniques.</p>
                
                <h3>üéØ Main Ideas</h3>
                <ul>
                    <li><strong>Subset Selection:</strong> Choosing the best subset of predictors</li>
                    <li><strong>Ridge Regression:</strong> Shrinkage method using L2 penalty</li>
                    <li><strong>Lasso Regression:</strong> Shrinkage method using L1 penalty</li>
                    <li><strong>Elastic Net:</strong> Combination of Ridge and Lasso</li>
                </ul>

                <div class="techniques">
                    <h4>üîß Key Techniques</h4>
                    <ul>
                        <li>Best Subset Selection</li>
                        <li>Forward/Backward Stepwise Selection</li>
                        <li>Ridge Regression</li>
                        <li>Lasso Regression</li>
                        <li>Elastic Net</li>
                        <li>Principal Components Regression</li>
                        <li>Partial Least Squares</li>
                    </ul>
                </div>

                <div class="formula">
                    <strong>Ridge:</strong> RSS + Œª‚àëŒ≤‚±º¬≤ | <strong>Lasso:</strong> RSS + Œª‚àë|Œ≤‚±º|
                </div>

                <h3>üí° Key Takeaways</h3>
                <p>Regularization techniques help prevent overfitting and can improve prediction accuracy. <span class="highlight">Ridge regression</span> shrinks coefficients, while <span class="highlight">Lasso</span> can perform variable selection by setting coefficients to zero.</p>

                <a href="https://github.com/kervis008/Data_Mining/blob/main/Chap05.ipynb" class="github-link">GitHub Lab Notebook - Chapter 5</a>
            </article>

            <article id="chapter6" class="chapter">
                <h2>Chapter 6: Tree-based Methods</h2>
                <p>Tree-based methods provide a completely different approach to regression and classification. They are highly interpretable and can capture complex non-linear relationships.</p>
                
                <h3>üéØ Main Ideas</h3>
                <ul>
                    <li><strong>Decision Trees:</strong> Hierarchical partitioning of feature space</li>
                    <li><strong>Pruning:</strong> Reducing tree complexity to prevent overfitting</li>
                    <li><strong>Random Forest:</strong> Ensemble of decision trees</li>
                    <li><strong>Boosting:</strong> Sequential improvement of weak learners</li>
                </ul>

                <div class="techniques">
                    <h4>üîß Key Techniques</h4>
                    <ul>
                        <li>Decision Trees (CART)</li>
                        <li>Cost Complexity Pruning</li>
                        <li>Random Forest</li>
                        <li>Gradient Boosting</li>
                        <li>AdaBoost</li>
                        <li>XGBoost</li>
                        <li>Bagging</li>
                    </ul>
                </div>

                <h3>üí° Key Takeaways</h3>
                <p>Tree-based methods are <span class="highlight">highly interpretable</span> and can handle both numerical and categorical variables. <span class="highlight">Ensemble methods</span> like Random Forest often provide better predictive performance than individual trees.</p>

                <a href="https://github.com/kervis008/Data_Mining/blob/main/Chap06%20Lab%20Non-Linear%20Modeling.ipynb" class="github-link">GitHub Lab Notebook - Chapter 6</a>
            </article>

            <article id="chapter7" class="chapter">
                <h2>Chapter 7: Support Vector Machines</h2>
                <p>Support Vector Machines (SVM) are powerful methods for both classification and regression that work well in high-dimensional spaces.</p>
                
                <h3>üéØ Main Ideas</h3>
                <ul>
                    <li><strong>Maximal Margin Classifier:</strong> Finding the optimal separating hyperplane</li>
                    <li><strong>Support Vector Classifier:</strong> Soft margin approach</li>
                    <li><strong>Support Vector Machine:</strong> Using kernels for non-linear boundaries</li>
                    <li><strong>Kernel Trick:</strong> Implicit mapping to higher dimensions</li>
                </ul>

                <div class="techniques">
                    <h4>üîß Key Techniques</h4>
                    <ul>
                        <li>Linear SVM</li>
                        <li>Polynomial Kernel</li>
                        <li>Radial Basis Function (RBF) Kernel</li>
                        <li>Support Vector Regression</li>
                        <li>Multi-class SVM</li>
                    </ul>
                </div>

                <h3>üí° Key Takeaways</h3>
                <p>SVMs are particularly effective for <span class="highlight">high-dimensional data</span> and can create complex decision boundaries through kernel functions. They are <span class="highlight">memory efficient</span> and work well with small to medium datasets.</p>

                <a href="https://github.com/kervis008/Data_Mining/blob/main/Chap09%20Lab-%20Support%20Vector%20Machines.ipynb" class="github-link">GitHub Lab Notebook - Chapter 7</a>
            </article>

            <article id="chapter8" class="chapter">
                <h2>Chapter 8: Deep Learning</h2>
                <p>Deep learning represents a major breakthrough in machine learning, using neural networks with multiple layers to learn complex patterns in data.</p>
                
                <h3>üéØ Main Ideas</h3>
                <ul>
                    <li><strong>Neural Networks:</strong> Networks of interconnected nodes</li>
                    <li><strong>Deep Networks:</strong> Multiple hidden layers</li>
                    <li><strong>Backpropagation:</strong> Algorithm for training neural networks</li>
                    <li><strong>Regularization:</strong> Dropout, weight decay, and early stopping</li>
                </ul>

                <div class="techniques">
                    <h4>üîß Key Techniques</h4>
                    <ul>
                        <li>Feedforward Neural Networks</li>
                        <li>Convolutional Neural Networks (CNNs)</li>
                        <li>Recurrent Neural Networks (RNNs)</li>
                        <li>Dropout Regularization</li>
                        <li>Batch Normalization</li>
                        <li>Transfer Learning</li>
                    </ul>
                </div>

                <h3>üí° Key Takeaways</h3>
                <p>Deep learning excels at <span class="highlight">pattern recognition</span> in complex, high-dimensional data. Success requires careful consideration of <span class="highlight">architecture design</span> and <span class="highlight">regularization techniques</span>.</p>
            </article>

            <article id="chapter9" class="chapter">
                <h2>Chapter 9: Unsupervised Learning</h2>
                <p>Unsupervised learning methods help discover hidden patterns in data without labeled examples, focusing on understanding the structure of data.</p>
                
                <h3>üéØ Main Ideas</h3>
                <ul>
                    <li><strong>Principal Component Analysis (PCA):</strong> Dimensionality reduction</li>
                    <li><strong>K-Means Clustering:</strong> Partitioning data into clusters</li>
                    <li><strong>Hierarchical Clustering:</strong> Creating tree-like cluster structures</li>
                    <li><strong>Association Rules:</strong> Finding relationships between variables</li>
                </ul>

                <div class="techniques">
                    <h4>üîß Key Techniques</h4>
                    <ul>
                        <li>Principal Component Analysis</li>
                        <li>K-Means Clustering</li>
                        <li>Hierarchical Clustering</li>
                        <li>DBSCAN</li>
                        <li>Gaussian Mixture Models</li>
                        <li>t-SNE</li>
                        <li>Market Basket Analysis</li>
                    </ul>
                </div>

                <h3>üí° Key Takeaways</h3>
                <p>Unsupervised learning is essential for <span class="highlight">exploratory data analysis</span> and <span class="highlight">data preprocessing</span>. These methods help identify patterns that might not be immediately obvious.</p>
            </article>

            <article id="chapter10" class="chapter">
                <h2>Chapter 10: Text Mining</h2>
                <p>Text mining involves extracting meaningful information from unstructured text data, combining statistical learning with natural language processing techniques.</p>
                
                <h3>üéØ Main Ideas</h3>
                <ul>
                    <li><strong>Text Preprocessing:</strong> Cleaning and preparing text data</li>
                    <li><strong>Feature Extraction:</strong> Converting text to numerical features</li>
                    <li><strong>Sentiment Analysis:</strong> Determining emotional tone</li>
                    <li><strong>Topic Modeling:</strong> Discovering themes in text collections</li>
                </ul>

                <div class="techniques">
                    <h4>üîß Key Techniques</h4>
                    <ul>
                        <li>Tokenization and Stemming</li>
                        <li>Term Frequency-Inverse Document Frequency (TF-IDF)</li>
                        <li>Bag of Words</li>
                        <li>N-grams</li>
                        <li>Latent Dirichlet Allocation (LDA)</li>
                        <li>Word Embeddings</li>
                        <li>Named Entity Recognition</li>
                    </ul>
                </div>

                <h3>üí° Key Takeaways</h3>
                <p>Text mining enables extraction of insights from <span class="highlight">unstructured text data</span>. Success depends on proper <span class="highlight">preprocessing</span> and choosing appropriate <span class="highlight">feature representation</span> methods.</p>
            </article>
        </main>

        <section class="algorithms-section">
            <h2>üßÆ Algorithm Summary</h2>
            
            <div class="algorithm-category">
                <h3>üìà Regression Algorithms</h3>
                <div class="algorithm-grid">
                    <div class="algorithm-card">
                        <h4>Linear Regression</h4>
                        <p>Basic linear relationship modeling using least squares estimation</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Ridge Regression</h4>
                        <p>L2 regularized linear regression that shrinks coefficients</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Lasso Regression</h4>
                        <p>L1 regularized regression with automatic feature selection</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Elastic Net</h4>
                        <p>Combination of Ridge and Lasso regularization</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Polynomial Regression</h4>
                        <p>Modeling non-linear relationships with polynomial features</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Support Vector Regression</h4>
                        <p>SVM applied to regression with epsilon-insensitive loss</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Decision Tree Regression</h4>
                        <p>Tree-based regression with interpretable rules</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Random Forest Regression</h4>
                        <p>Ensemble of regression trees with bootstrap aggregating</p>
                    </div>
                </div>
            </div>

            <div class="algorithm-category">
                <h3>üéØ Classification Algorithms</h3>
                <div class="algorithm-grid">
                    <div class="algorithm-card">
                        <h4>Logistic Regression</h4>
                        <p>Linear classification using logistic function</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Linear Discriminant Analysis</h4>
                        <p>Bayes-based classification with linear boundaries</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Quadratic Discriminant Analysis</h4>
                        <p>More flexible version of LDA with quadratic boundaries</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>K-Nearest Neighbors</h4>
                        <p>Instance-based classification using local similarity</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Naive Bayes</h4>
                        <p>Probabilistic classifier with feature independence assumption</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Support Vector Machine</h4>
                        <p>Maximum margin classification with kernel trick</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Decision Trees</h4>
                        <p>Rule-based classification with hierarchical splits</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Random Forest</h4>
                        <p>Ensemble of decision trees with voting</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Gradient Boosting</h4>
                        <p>Sequential ensemble method with gradient optimization</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Neural Networks</h4>
                        <p>Deep learning with multiple hidden layers</p>
                    </div>
                </div>
            </div>

            <div class="algorithm-category">
                <h3>üîç Unsupervised Learning Algorithms</h3>
                <div class="algorithm-grid">
                    <div class="algorithm-card">
                        <h4>K-Means Clustering</h4>
                        <p>Centroid-based clustering with distance minimization</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Hierarchical Clustering</h4>
                        <p>Tree-based clustering with agglomerative/divisive methods</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>DBSCAN</h4>
                        <p>Density-based clustering with noise detection</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Principal Component Analysis</h4>
                        <p>Linear dimensionality reduction preserving variance</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>t-SNE</h4>
                        <p>Non-linear dimensionality reduction for visualization</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Gaussian Mixture Models</h4>
                        <p>Probabilistic clustering with expectation-maximization</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Association Rules</h4>
                        <p>Market basket analysis for frequent patterns</p>
                    </div>
                    <div class="algorithm-card">
                        <h4>Latent Dirichlet Allocation</h4>
                        <p>Topic modeling for discovering themes in text</p>
                    </div>
                </div>
            </div>
        </section>

        <footer>
            <h3>üöÄ GitHub Repository</h3>
            <p>All lab notebooks and code examples are available at:</p>
            <a href="https://github.com/kervis008/Data_Mining" 
               style="color: #a8e6cf; text-decoration: none; font-weight: bold; font-size: 1.2em;">
                üìÇ Data Mining Course Repository
            </a>
            <br><br>
            <p><em>Course completed with practical implementations in Python using scikit-learn, pandas, and matplotlib</em></p>
            <p style="margin-top: 15px; font-size: 0.9em; opacity: 0.8;">
                Created for academic purposes | Data Mining Course with Python Implementation
            </p>
        </footer>
    </div>

    <script>
        // Create animated background particles
        function createParticles() {
            const particlesContainer = document.querySelector('.particles');
            const particleCount = 50;
            
            for (let i = 0; i < particleCount; i++) {
                const particle = document.createElement('div');
                particle.className = 'particle';
                particle.style.left = Math.random() * 100 + '%';
                particle.style.animationDuration = (Math.random() * 3 + 3) + 's';
                particle.style.animationDelay = Math.random() * 6 + 's';
                particlesContainer.appendChild(particle);
            }
        }

        // Update scroll progress bar
        function updateScrollProgress() {
            const scrollTop = window.pageYOffset || document.documentElement.scrollTop;
            const scrollHeight = document.documentElement.scrollHeight - document.documentElement.clientHeight;
            const scrollProgress = (scrollTop / scrollHeight) * 100;
            
            const progressBar = document.querySelector('.scroll-progress');
            progressBar.style.width = scrollProgress + '%';
        }

        // Add smooth scrolling for navigation links
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });

        // Enhanced hover effects for algorithm cards
        document.querySelectorAll('.algorithm-card').forEach(card => {
            card.addEventListener('mouseenter', function() {
                this.style.transform = 'translateY(-15px) scale(1.05) rotateX(5deg)';
                this.style.boxShadow = '0 25px 60px rgba(74, 71, 163, 0.4)';
            });
            
            card.addEventListener('mouseleave', function() {
                this.style.transform = 'translateY(0) scale(1) rotateX(0deg)';
                this.style.boxShadow = '0 4px 15px rgba(0, 0, 0, 0.1)';
            });
        });

        // Enhanced GitHub link interactions
        document.querySelectorAll('.github-link').forEach(link => {
            link.addEventListener('mouseenter', function() {
                this.style.transform = 'translateY(-5px) scale(1.08)';
                this.style.boxShadow = '0 20px 50px rgba(40, 167, 69, 0.5)';
            });
            
            link.addEventListener('mouseleave', function() {
                this.style.transform = 'translateY(0) scale(1)';
                this.style.boxShadow = '0 8px 25px rgba(40, 167, 69, 0.3)';
            });
        });

        // Chapter highlighting in table of contents
        function highlightActiveChapter() {
            const chapters = document.querySelectorAll('.chapter');
            const tocLinks = document.querySelectorAll('.toc a');
            
            chapters.forEach((chapter, index) => {
                const rect = chapter.getBoundingClientRect();
                const tocLink = tocLinks[index];
                
                if (rect.top <= 150 && rect.bottom >= 150) {
                    tocLinks.forEach(link => {
                        link.style.fontWeight = 'normal';
                        link.style.color = '#333';
                    });
                    if (tocLink) {
                        tocLink.style.fontWeight = 'bold';
                        tocLink.style.color = '#4a47a3';
                        tocLink.style.textShadow = '0 0 10px rgba(74, 71, 163, 0.3)';
                    }
                }
            });
        }

        // Fade-in animation for chapters
        const observerOptions = {
            threshold: 0.1,
            rootMargin: '0px 0px -50px 0px'
        };

        const observer = new IntersectionObserver(function(entries) {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.style.opacity = '1';
                    entry.target.style.transform = 'translateY(0) perspective(1000px) rotateY(0deg)';
                }
            });
        }, observerOptions);

        // Initialize animations
        function initializeAnimations() {
            // Set initial states for chapters
            document.querySelectorAll('.chapter').forEach(chapter => {
                chapter.style.opacity = '0';
                chapter.style.transform = 'translateY(50px) perspective(1000px) rotateY(5deg)';
                chapter.style.transition = 'all 0.8s cubic-bezier(0.175, 0.885, 0.32, 1.275)';
                observer.observe(chapter);
            });

            // Set initial states for algorithm cards
            document.querySelectorAll('.algorithm-card').forEach((card, index) => {
                card.style.opacity = '0';
                card.style.transform = 'translateY(30px)';
                card.style.transition = `all 0.6s ease ${index * 0.1}s`;
                
                setTimeout(() => {
                    card.style.opacity = '1';
                    card.style.transform = 'translateY(0)';
                }, 100 + (index * 100));
            });
        }

        // Parallax effect for header
        function parallaxHeader() {
            const scrolled = window.pageYOffset;
            const parallax = document.querySelector('header');
            const speed = scrolled * 0.5;
            parallax.style.transform = `translateY(${speed}px)`;
        }

        // Event listeners
        window.addEventListener('scroll', () => {
            updateScrollProgress();
            highlightActiveChapter();
            parallaxHeader();
        });

        window.addEventListener('load', () => {
            createParticles();
            initializeAnimations();
        });

        // Add typing effect to subtitle
        function typeWriter() {
            const subtitle = document.querySelector('.subtitle');
            const text = subtitle.textContent;
            subtitle.textContent = '';
            subtitle.style.opacity = '1';
            
            let i = 0;
            function type() {
                if (i < text.length) {
                    subtitle.textContent += text.charAt(i);
                    i++;
                    setTimeout(type, 50);
                }
            }
            setTimeout(type, 1000);
        }

        // Initialize typing effect
        setTimeout(typeWriter, 500);

        console.log('üé® Enhanced Data Mining Course Summary loaded!');
        console.log('‚ú® Features: 3D animations, particles, parallax, enhanced interactions');
        console.log('üîó All GitHub links updated to your repository structure!');
    </script>
</body>
</html>
